<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WOOFY - Dog Body Language Decoder (Image Analysis)</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Configure Tailwind for custom colors and font -->
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'woofy-blue': '#10b981', // Emerald green (Primary)
                        'woofy-dark': '#1f2937', // Dark gray (Text/Header)
                        'woofy-light': '#f9fafb', // Light gray/off-white (Background)
                        'woofy-red': '#ef4444', // Red (Action/WOOF button)
                        'woofy-yellow': '#f59e0b', // Amber (Secondary Upload - kept for styling consistency)
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                }
            }
        }
    </script>
    <style>
        /* Custom scrollbar styling for better aesthetics */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #e5e7eb;
        }
        ::-webkit-scrollbar-thumb {
            background: #6b7280;
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #4b5563;
        }
        /* Loading spinner animation */
        .spinner {
            border: 4px solid rgba(0, 0, 0, 0.1);
            border-left-color: #10b981;
            border-radius: 50%;
            width: 24px;
            height: 24px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        /* Ensure responsive height for mobile view */
        #app-container {
            min-height: 100vh;
        }
        /* Style for video and image/canvas elements */
        #video, #imagePreview {
            width: 100%;
            height: auto;
            max-width: 100%;
            border-radius: 12px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
            background-color: #000; /* Black background for media area */
            object-fit: contain; /* Ensures entire image/video is visible */
        }
        #capturedCanvas {
            /* Keep canvas hidden, it's just for processing */
            display: none;
        }
        .step-title {
            @apply text-xl font-semibold text-woofy-dark mb-3 flex items-center space-x-2;
        }
        /* File Input Styling */
        input[type="file"] {
            display: none;
        }

        /* Highlight the media area when an image is ready for analysis */
        .media-ready {
            border: 4px solid #10b981 !important; /* Woofy Blue highlight */
            box-shadow: 0 0 10px rgba(16, 185, 129, 0.5);
        }

        /* Custom style for the output report card */
        #aiResponse {
            background-color: white; 
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -4px rgba(0, 0, 0, 0.1); /* Lighter shadow for the report */
            border: 1px solid #e5e7eb;
        }
    </style>
</head>
<body class="bg-woofy-light font-sans antialiased">

    <div id="app-container" class="max-w-4xl mx-auto p-4 sm:p-6 lg:p-8 flex flex-col items-center">

        <!-- Header -->
        <header class="w-full text-center mb-8">
            <h1 class="text-5xl font-extrabold text-woofy-dark tracking-tight mb-2">
                WOOFY <span class="text-woofy-blue text-3xl">üêæ</span>
            </h1>
            <p class="text-lg text-gray-500 italic">Capture, upload, and decode the moment.</p>
        </header>

        <!-- Main Card Container -->
        <div class="w-full bg-white shadow-xl rounded-2xl p-6 md:p-10 border border-gray-100">

            <!-- 1. Media Input Area -->
            <section class="mb-8 p-4 border border-gray-200 rounded-xl bg-gray-50">
                <h2 class="step-title">
                    <span>1. Capture or Upload</span>
                </h2>

                <!-- Input Buttons (Simplified 2-Column Grid) -->
                <div class="grid grid-cols-1 sm:grid-cols-2 gap-3 mb-4">
                    <button id="cameraButton" onclick="toggleCamera()"
                        class="px-4 py-3 bg-woofy-blue text-white font-medium rounded-lg shadow hover:bg-woofy-blue/90 transition disabled:bg-gray-400 active:scale-[0.98]">
                        Use Camera
                    </button>
                    <!-- File input for images -->
                    <input type="file" id="imageFileInput" accept="image/*" onchange="handleFileSelect(event)">
                    <label for="imageFileInput" class="flex items-center justify-center px-4 py-3 bg-gray-600 text-white font-medium rounded-lg shadow cursor-pointer hover:bg-gray-700 transition active:scale-[0.98]">
                        Upload Image
                    </label>
                </div>


                <div id="mediaArea" class="relative mb-4">
                    <!-- Video element is kept but hidden/not used for simplicity -->
                    <video id="video" playsinline class="hidden"></video>
                    <!-- Image element for captured preview (initially hidden) -->
                    <img id="imagePreview" class="hidden" alt="Captured dog image">

                    <!-- Canvas element to hold the captured frame (hidden from view) -->
                    <canvas id="capturedCanvas"></canvas>

                    <!-- Placeholder/Message -->
                    <div id="mediaPlaceholder" class="flex items-center justify-center h-48 bg-gray-200 rounded-xl text-gray-500">
                        Start your camera or upload a file above.
                    </div>

                    <!-- Error/Permission message -->
                    <p id="videoMessage" class="hidden text-center text-red-600 p-4"></p>
                </div>

                <!-- Capture Button (Only used for live camera now) -->
                <button id="captureButton" onclick="captureFrame()" disabled
                    class="w-full flex items-center justify-center space-x-2 px-6 py-3 bg-woofy-red text-white font-bold text-base rounded-full shadow-lg hover:shadow-woofy-red/50 transform hover:scale-[1.01] transition duration-200 focus:outline-none focus:ring-4 focus:ring-woofy-red/70 focus:ring-offset-2 disabled:bg-gray-400 disabled:cursor-not-allowed active:scale-[0.98]">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="w-5 h-5">
                        <path d="M4.5 4.5a3 3 0 00-3 3v9a3 3 0 003 3h15a3 3 0 003-3v-9a3 3 0 00-3-3h-1.373a1.5 1.5 0 01-1.06-.395l-1.428-1.428A1.5 1.5 0 0013.06 2.25h-4.125a1.5 1.5 0 00-1.06.395L6.873 7.5a.75.75 0 01-.53.197H4.5z" />
                        <path fill-rule="evenodd" d="M12 12a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd" />
                        <path fill-rule="evenodd" d="M12 18a6 6 0 100-12 6 6 0 000 12zM12 16a4 4 0 100-8 4 4 0 000 8z" clip-rule="evenodd" />
                    </svg>
                    <span id="captureButtonText">Capture Frame</span>
                </button>
            </section>


            <!-- 2. Context Input Area -->
            <section class="mb-8">
                <h2 class="step-title">
                    <span>2. Add Context (Optional)</span>
                </h2>
                <textarea id="bodyLanguageInput" rows="2" placeholder="Example: They are meeting a new dog / She is waiting for me to throw the ball."
                    class="w-full p-3 border border-gray-300 rounded-xl focus:border-woofy-blue focus:ring-2 focus:ring-offset-2 focus:ring-woofy-blue transition duration-150 resize-none text-gray-700"></textarea>
            </section>

            <!-- 3. Action Button (The "WOOF!" button) -->
            <div class="flex justify-center mb-8">
                <button id="decodeButton" onclick="decodeBodyLanguage()" disabled
                    class="flex items-center justify-center space-x-2 px-12 py-5 bg-woofy-red text-white font-black text-2xl uppercase rounded-full shadow-2xl shadow-woofy-red/40 transform hover:scale-[1.05] transition duration-200 focus:outline-none focus:ring-8 focus:ring-woofy-red/80 focus:ring-offset-2 disabled:bg-gray-400 disabled:cursor-not-allowed active:scale-[0.98]">
                    <span id="buttonText">WOOF!</span>
                    <div id="loadingSpinner" class="spinner hidden w-6 h-6 border-4"></div>
                </button>
            </div>

            <!-- Output Area -->
            <section id="outputArea" class="hidden">
                <h2 class="text-2xl font-bold text-woofy-dark border-b-2 border-woofy-blue pb-2 mb-4">
                    WOOFY's Analysis
                </h2>
                <div id="aiResponse" class="p-4 bg-woofy-light border border-gray-200 rounded-xl text-gray-800 leading-relaxed min-h-[100px] overflow-auto max-h-[50vh]">
                    <!-- AI content will be inserted here -->
                </div>

                <!-- Grounding Sources -->
                <div id="sourcesContainer" class="mt-4 text-sm text-gray-500">
                    <!-- Sources will be inserted here -->
                </div>
            </section>

             <!-- Error Message Area -->
             <div id="errorMessage" class="hidden mt-4 p-3 bg-red-100 border border-red-400 text-red-700 rounded-lg">
                <p class="font-medium">Error:</p>
                <p id="errorText"></p>
            </div>

        </div>
    </div>

    <script>
        // Global constants and variables
        const API_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta/models';
        const MODEL_NAME = 'gemini-2.5-flash-preview-05-20';
        // The API Key is intentionally left blank. In this Google-hosted environment, 
        // the API key is automatically supplied via a proxy for security and ease of use.
        const apiKey = ""; 

        // DOM Elements
        const videoElement = document.getElementById('video');
        const imagePreviewElement = document.getElementById('imagePreview');
        const capturedCanvas = document.getElementById('capturedCanvas');
        const videoMessage = document.getElementById('videoMessage');
        const mediaPlaceholder = document.getElementById('mediaPlaceholder');
        const inputElement = document.getElementById('bodyLanguageInput');
        const captureButton = document.getElementById('captureButton');
        const cameraButton = document.getElementById('cameraButton');
        const decodeButton = document.getElementById('decodeButton');
        const buttonText = document.getElementById('buttonText');
        const loadingSpinner = document.getElementById('loadingSpinner');
        const outputArea = document.getElementById('outputArea');
        const aiResponse = document.getElementById('aiResponse');
        const sourcesContainer = document.getElementById('sourcesContainer');
        const errorMessage = document.getElementById('errorMessage');
        const errorText = document.getElementById('errorText');
        const mediaArea = document.getElementById('mediaArea'); // Reference for styling

        // State variables
        let videoStream = null;
        let capturedImageBase64 = null;
        let isCameraActive = false;

        // Ensure elements are hidden/visible correctly on load
        document.addEventListener('DOMContentLoaded', () => {
            imagePreviewElement.classList.add('hidden');
            videoElement.classList.add('hidden');
            mediaPlaceholder.classList.remove('hidden');
        });


        /**
         * System instruction defining the AI's role and output format for image analysis.
         */
        const systemPrompt = `
            Act as a certified professional dog behavior expert. You are analyzing an image provided by the user, which may contain one or multiple dogs, along with any contextual text description.
            Your goal is to analyze all visual body language cues, paying special attention to **inter-dog communication, spatial relationships, and dynamic interaction signals** (e.g., play bows, tension, resource guarding, appeasement).
            Provide a concise, empathetic, and authoritative response in Markdown.

            Your output MUST contain two distinct, bolded sections based on established canine behavioral science:
            1. **Interpretation**: State the dogs' likely emotional states and the overall nature of their interaction (e.g., appropriate play, stress signals, resource conflict).
            2. **Actionable Advice**: Offer 1-2 practical, immediate steps the owner should take based on the interaction dynamic, referencing the captured moment.

            Do not include any introductory or concluding remarks outside of the two sections.
            The response must be grounded in reliable external sources.
        `;

        /**
         * Stops the current camera stream if one is active.
         */
        function stopCamera() {
            if (videoStream) {
                videoStream.getTracks().forEach(track => track.stop());
                videoStream = null;
                isCameraActive = false;
                videoElement.srcObject = null;
                cameraButton.textContent = "Use Camera";
            }
        }

        /**
         * Toggles the live camera stream.
         */
        async function toggleCamera() {
            if (isCameraActive) {
                // If camera is active, stop it
                stopCamera();
                videoElement.classList.add('hidden');
                mediaPlaceholder.classList.remove('hidden');
                captureButton.disabled = true;
                return;
            }

            // Hide placeholder and previous media
            mediaPlaceholder.classList.add('hidden');
            imagePreviewElement.classList.add('hidden');
            videoElement.classList.remove('hidden');
            videoMessage.classList.add('hidden');
            mediaArea.classList.remove('media-ready'); // Remove highlight

            // Request the rear-facing camera first
            const videoConstraints = {
                video: {
                    facingMode: 'environment' // Request rear camera
                }
            };

            // Activate camera
            try {
                // Try to get the environment camera
                let stream = await navigator.mediaDevices.getUserMedia(videoConstraints);
                videoElement.srcObject = stream;
                videoStream = stream;
                isCameraActive = true;
                videoElement.play(); // Start playback
                cameraButton.textContent = "Stop Camera";
                captureButton.disabled = false;

            } catch (err) {
                // Fallback: If 'environment' fails, try any camera.
                try {
                    let stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    videoElement.srcObject = stream;
                    videoStream = stream;
                    isCameraActive = true;
                    videoElement.play();
                    cameraButton.textContent = "Stop Camera";
                    captureButton.disabled = false;
                } catch (fallbackError) {
                    // Both attempts failed
                    console.error("Error accessing the camera: ", fallbackError);
                    videoElement.classList.add('hidden');
                    mediaPlaceholder.classList.remove('hidden');
                    videoMessage.textContent = 'Camera access failed. Please ensure you are on HTTPS and granted permissions.';
                    videoMessage.classList.remove('hidden');
                    captureButton.disabled = true;
                    isCameraActive = false;
                }
            }
        }

        /**
         * Handles file selection (Image only now) and loads it into the appropriate element.
         * The 'fileType' parameter is no longer needed but kept in the HTML call for structure.
         */
        function handleFileSelect(event) {
            const file = event.target.files[0];
            if (!file) return;

            // Stop camera if running
            stopCamera();

            // Hide placeholder and error messages
            mediaPlaceholder.classList.add('hidden');
            hideError();

            const fileUrl = URL.createObjectURL(file);
            mediaArea.classList.remove('media-ready'); // Remove highlight initially

            // Handle Image Upload
            videoElement.classList.add('hidden');
            imagePreviewElement.src = fileUrl;
            imagePreviewElement.classList.remove('hidden');

            // When the image loads, automatically capture the frame to generate Base64 data.
            imagePreviewElement.onload = () => {
                captureFrame(true); // true tells captureFrame to flash the button text
                imagePreviewElement.onload = null; // Remove the listener
            };

            capturedImageBase64 = null;
            captureButton.disabled = true; // Disable capture button as we auto-capture the image
            decodeButton.disabled = true;
        }

        /**
         * Captures a single frame from the current media source (live camera or uploaded image).
         * @param {boolean} isImageUpload - True if called automatically after an image upload.
         */
        function captureFrame(isImageUpload = false) {
            const isVideoReady = !videoElement.classList.contains('hidden') && videoElement.readyState >= 2;
            const isImageReady = !imagePreviewElement.classList.contains('hidden') && imagePreviewElement.src;

            if (!isVideoReady && !isImageReady) {
                showError("Please load media (live camera or image) before capturing a frame.");
                return;
            }

            // Determine source dimensions
            let source = isImageReady ? imagePreviewElement : videoElement;
            const sourceWidth = source.naturalWidth || source.videoWidth;
            const sourceHeight = source.naturalHeight || source.videoHeight;

            if (sourceWidth === 0 || sourceHeight === 0) {
                 showError("Media source is not ready. Please ensure the camera is active or the image has fully loaded.");
                 return;
            }

            // Set canvas dimensions
            capturedCanvas.width = sourceWidth;
            capturedCanvas.height = sourceHeight;

            // Draw the current frame/image onto the canvas
            const ctx = capturedCanvas.getContext('2d');
            ctx.drawImage(source, 0, 0, sourceWidth, sourceHeight);

            // Convert canvas content to a base64 data URL
            const dataUrl = capturedCanvas.toDataURL('image/jpeg', 0.8); // 80% quality for smaller size

            // Format for Gemini API (remove the data URI header)
            capturedImageBase64 = dataUrl.split(',')[1];

            // Display the captured image preview 
            imagePreviewElement.src = dataUrl;
            imagePreviewElement.classList.remove('hidden');
            videoElement.classList.add('hidden'); // Hide video element

            // Update UI state
            captureButton.textContent = "Capture New Frame";
            decodeButton.disabled = false;
            hideError();
            mediaArea.classList.add('media-ready'); // Highlight that analysis is ready!

            // If we automatically captured an uploaded image, we update the capture button text briefly
            if (isImageUpload) {
                // If it was an upload, the Capture Frame button is not needed, but we provide feedback
                captureButton.disabled = true;
                captureButton.textContent = "Image Ready!";
                setTimeout(() => {
                    if (captureButton.textContent === "Image Ready!") {
                        captureButton.textContent = "Capture New Frame"; // Revert after a moment
                    }
                }, 1500);
            }
        }

        /**
         * Utility function to handle API calls with exponential backoff for retries.
         */
        async function fetchWithRetries(url, options, retries = 3) {
            for (let i = 0; i < retries; i++) {
                try {
                    const response = await fetch(url, options);
                    if (response.status === 429) {
                        if (i < retries - 1) {
                            const delay = Math.pow(2, i) * 1000; // Exponential backoff: 1s, 2s, 4s
                            await new Promise(resolve => setTimeout(resolve, delay));
                            continue;
                        }
                    }
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    return response;
                } catch (error) {
                    if (i === retries - 1) throw error;
                    const delay = Math.pow(2, i) * 1000;
                    await new Promise(resolve => setTimeout(resolve, delay));
                }
            }
        }

        /**
         * 3. Main function to call the Gemini API with the image and text prompt.
         */
        async function decodeBodyLanguage() {
            if (!capturedImageBase64) {
                showError("Please capture an image of your dog before analyzing. If you uploaded a photo, wait for the 'WOOF!' button to activate.");
                return;
            }

            const userQuery = inputElement.value.trim() || "Analyze the body language of the dog in this photo.";

            // UI State: Loading
            setLoading(true);
            hideError();
            mediaArea.classList.remove('media-ready'); // Remove highlight while analyzing

            const apiUrl = `${API_BASE_URL}/${MODEL_NAME}:generateContent?key=${apiKey}`;

            const payload = {
                contents: [{
                    parts: [
                        { text: userQuery },
                        {
                            inlineData: {
                                mimeType: "image/jpeg",
                                data: capturedImageBase64
                            }
                        }
                    ]
                }],
                // Enable Google Search grounding
                tools: [{ "google_search": {} }],
                // Apply the expert persona
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };

            try {
                const response = await fetchWithRetries(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();
                const candidate = result.candidates?.[0];

                if (candidate && candidate.content?.parts?.[0]?.text) {
                    const text = candidate.content.parts[0].text;
                    let sources = [];

                    // Extract grounding sources
                    const groundingMetadata = candidate.groundingAttributions;
                    if (groundingMetadata && groundingMetadata.groundingAttributions) {
                        sources = groundingMetadata.groundingAttributions
                            .map(attribution => ({
                                uri: attribution.web?.uri,
                                title: attribution.web?.title,
                            }))
                            .filter(source => source.uri && source.title);
                    }

                    displayResults(text, sources);

                } else {
                    throw new Error("Received an empty or malformed response from the AI.");
                }

            } catch (error) {
                console.error('API Call Error:', error);
                showError(`Failed to analyze the image. Please try again. (${error.message})`);
            } finally {
                // UI State: Done
                setLoading(false);
            }
        }

        /**
         * Updates the UI to show the AI response and sources.
         */
        function displayResults(text, sources) {
            // Simple Markdown-to-HTML conversion for bolding and paragraphs
            let htmlContent = text
                .replace(/\*\*(.*?)\*\*/g, '<strong class="text-woofy-dark">$1</strong>') // Bold text
                .replace(/\n\n/g, '</p><p class="mt-2">') // Paragraphs
                .replace(/\n/g, '<br/>'); // Line breaks

            aiResponse.innerHTML = `<p class="p-2">${htmlContent}</p>`;
            outputArea.classList.remove('hidden');

            // Display Sources
            sourcesContainer.innerHTML = '';
            if (sources.length > 0) {
                const sourceListHtml = sources.map(source =>
                    `<a href="${source.uri}" target="_blank" rel="noopener noreferrer" class="text-woofy-blue hover:underline block text-xs">
                        ‚Ä¢ ${source.title}
                    </a>`
                ).join('');

                sourcesContainer.innerHTML = `
                    <p class="font-semibold mb-1 text-gray-600">Sources used for grounding this advice:</p>
                    <div class="space-y-1">
                        ${sourceListHtml}
                    </div>
                `;
            }
        }

        /**
         * Manages the loading state of the button and input.
         */
        function setLoading(isLoading) {
            decodeButton.disabled = isLoading || !capturedImageBase64;
            captureButton.disabled = isLoading || !isCameraActive; // Only disable capture if loading or camera is not active
            inputElement.disabled = isLoading;

            if (isLoading) {
                buttonText.textContent = 'ANALYZING...';
                loadingSpinner.classList.remove('hidden');
            } else {
                buttonText.textContent = 'WOOF!';
                loadingSpinner.classList.add('hidden');
            }
        }

        /**
         * Displays an error message.
         */
        function showError(message) {
            errorText.textContent = message;
            errorMessage.classList.remove('hidden');
            outputArea.classList.add('hidden');
        }

        /**
         * Hides any existing error message.
         */
        function hideError() {
            errorMessage.classList.add('hidden');
        }

    </script>
</body>
</html>
